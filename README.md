# ğŸ” AnÃ¡lisis de Abandono de Clientes con Machine Learning
![Machine Learning](https://image.lexica.art/full_webp/5456ffbd-a76d-47b2-b3a8-60041eeb9795)
Un proyecto completo de anÃ¡lisis predictivo para identificar patrones de abandono de clientes utilizando mÃºltiples algoritmos de machine learning y evaluaciÃ³n comparativa de rendimiento.

## ğŸ“Š DescripciÃ³n del Proyecto

Este proyecto implementa un sistema de anÃ¡lisis predictivo para determinar la probabilidad de abandono (churn) de clientes utilizando tÃ©cnicas avanzadas de machine learning. El objetivo principal es comparar el rendimiento de diferentes algoritmos para identificar cuÃ¡l proporciona la mejor precisiÃ³n predictiva.

## ğŸ¯ Objetivos

- Analizar patrones de comportamiento que indican abandono de clientes
- Implementar mÃºltiples algoritmos de clasificaciÃ³n
- Evaluar y comparar el rendimiento de cada modelo
- Identificar las caracterÃ­sticas mÃ¡s importantes que influyen en el abandono
- Proporcionar insights accionables para la retenciÃ³n de clientes

## ğŸ“‚ Estructura del Proyecto

```
proyecto-churn-analysis/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Datos originales
â”‚   â”œâ”€â”€ processed/              # Datos procesados
â”‚   â””â”€â”€ external/               # Datos externos
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploratory_analysis.ipynb
â”‚   â”œâ”€â”€ 02_data_preprocessing.ipynb
â”‚   â”œâ”€â”€ 03_model_training.ipynb
â”‚   â””â”€â”€ 04_model_evaluation.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/                   # Scripts de procesamiento
â”‚   â”œâ”€â”€ models/                 # Modelos implementados
â”‚   â”œâ”€â”€ visualization/          # Visualizaciones
â”‚   â””â”€â”€ utils/                  # Utilidades
â”œâ”€â”€ models/                     # Modelos entrenados
â”œâ”€â”€ reports/                    # Reportes y anÃ¡lisis
â””â”€â”€ requirements.txt
```

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Google Colab**
- **Pandas** - ManipulaciÃ³n de datos
- **NumPy** - Operaciones numÃ©ricas
- **Scikit-learn** - Algoritmos de ML
- **XGBoost** - Gradient boosting
- **LightGBM** - Gradient boosting ligero
- **Matplotlib/Seaborn** - VisualizaciÃ³n
- **Plotly** - Visualizaciones interactivas

## ğŸ¤– Algoritmos Implementados

### Algoritmos de ClasificaciÃ³n
                        
LightGBM                
Gradient Boosting       
Logistic Regression     
XGBoost                 
Random Forest          
K-Nearest Neighbors    
Support Vector Machine  
Decision Tree

## ğŸ“ˆ MÃ©tricas de EvaluaciÃ³n

- **Accuracy** - PrecisiÃ³n general
- **Precision** - PrecisiÃ³n por clase
- **Recall** - Sensibilidad
- **F1-Score** - Media armÃ³nica de precision y recall
- **ROC-AUC** - Ãrea bajo la curva ROC
- **Precision-Recall AUC** - Ãrea bajo la curva PR
- **Matriz de ConfusiÃ³n** - AnÃ¡lisis detallado de predicciones

## ğŸš€ InstalaciÃ³n y Uso

### Prerrequisitos
```bash
git clone https://github.com/tu-usuario/churn-analysis-ml.git
cd churn-analysis-ml
```

### InstalaciÃ³n de dependencias
```bash
pip install -r requirements.txt
```

### EjecuciÃ³n del anÃ¡lisis
```bash
# Ejecutar anÃ¡lisis exploratorio
jupyter notebook notebooks/01_exploratory_analysis.ipynb

# Procesar datos
python src/data/preprocess_data.py

# Entrenar modelos
python src/models/train_models.py

# Evaluar modelos
python src/models/evaluate_models.py
```

## ğŸ“Š Resultados Principales

### ComparaciÃ³n de Modelos
---
## ComparaciÃ³n de Modelos

A continuaciÃ³n, se presenta una tabla comparativa de los resultados de diferentes modelos:

| Modelo                  | Accuracy | Precision | Recall   | F1-Score | ROC AUC  | Training Time |
| :---------------------- | :------- | :-------- | :------- | :------- | :------- | :------------ |
| **LightGBM** | 0.814009 | 0.679487  | 0.566845 | 0.618076 | 0.852304 | 0.190744      |
| **Gradient Boosting** | 0.811642 | 0.670860  | 0.570410 | 0.616570 | 0.856820 | 1.090859      |
| **Logistic Regression** | 0.804070 | 0.647887  | 0.573975 | 0.608696 | 0.848263 | 0.029151      |
| **XGBoost** | 0.794605 | 0.631470  | 0.543672 | 0.584291 | 0.832934 | 0.199656      |
| **Random Forest** | 0.781827 | 0.600402  | 0.532977 | 0.564684 | 0.814406 | 1.505419      |
| **K-Nearest Neighbors** | 0.770469 | 0.572519  | 0.534759 | 0.552995 | 0.782056 | 0.201206      |
| **Support Vector Machine** | 0.792712 | 0.669421 | 0.433155 | 0.525974 | 0.806785 | 5.421773      |
| **Decision Tree** | 0.731661 | 0.494755  | 0.504456 | 0.499559 | 0.662563 | 0.035676      |

---

## ğŸ”§ Preprocesamiento de Datos

- **Limpieza**: Manejo de valores faltantes y outliers
- **Encoding**: CodificaciÃ³n de variables categÃ³ricas
- **Scaling**: NormalizaciÃ³n de variables numÃ©ricas
- **Feature Engineering**: CreaciÃ³n de nuevas caracterÃ­sticas
- **Balanceo**: TÃ©cnicas SMOTE para clases desbalanceadas

## ğŸ“ Insights y Recomendaciones
---
### Correlaciones negativas fuertes (factores protectores):

1.  **Tipo_contrato**: -0.397 (La mÃ¡s fuerte - contratos largos protegen del abandono)
2.  **AntigÃ¼edad_meses**: -0.352 (Clientes antiguos cancelan menos)
3.  **Seguridad_en_lÃ­nea**: -0.289 (Tener seguridad reduce abandono)
4.  **Soporte_tÃ©cnico**: -0.282 (Soporte tÃ©cnico es protector)
5.  **Cargo_total**: -0.199 (Sorprendentemente, mayor cargo total = menos cancelaciÃ³n)

---
### Correlaciones positivas (factores de riesgo):

1.  **Cargo_mensual**: 0.193 (Cargos mensuales altos aumentan abandono)
2.  **Cuentas_Diarias**: 0.193 (Igual valor que cargo mensual)
3.  **Factura_sin_papel**: 0.192 (FacturaciÃ³n digital se asocia con mÃ¡s abandono)
4.  **Tiene_dependientes**: -0.164 (Tener dependientes es protector)
5.  **Adulto_mayor**: 0.151 (Adultos mayores tienden a cancelar mÃ¡s)

---
### Insights importantes:

1.  Los **contratos a largo plazo** son el factor protector mÃ¡s fuerte.
2.  Existe una **paradoja del cargo**: un mayor cargo total (acumulativo) resulta en menos abandono, pero un mayor cargo mensual se asocia con mÃ¡s abandono.
3.  Los **servicios adicionales** (como seguridad y soporte) actÃºan como "pegamento" para retener clientes.
4.  La **antigÃ¼edad es clave**: cuanto mÃ¡s tiempo lleva un cliente, menos probable es que cancele.

## ğŸ¤ Contribuciones  

Las contribuciones son bienvenidas. Por favor:  

1. Fork el proyecto  
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE.md](LICENSE.md) para mÃ¡s detalles.

## ğŸ‘¥ Autores

- **Angel Troncoso** - *Desarrollo inicial* - [tu-github](https://github.com/AngelTroncoso)

## ğŸ™ Agradecimientos

- Dataset proporcionado por [Alura Latam]
- Comunidad de Kaggle por los insights
- Contribuidores de las librerÃ­as open source utilizadas

## ğŸ“ Contacto

- Email: angeltroncoso2019@outlook.es
- LinkedIn: [Angel Troncoso](https://www.linkedin.com/in/angeltroncoso/)
- Twitter: [Angel Troncoso](https://x.com/AngelTronc26452)

---

â­ **Â¡Dale una estrella al proyecto si te pareciÃ³ Ãºtil!**
